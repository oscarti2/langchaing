{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oscarti2/langchaing/blob/main/sistema_de_respuesta_a_preguntas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b531635",
      "metadata": {
        "id": "0b531635"
      },
      "source": [
        "* Cargar los datos de los \"documentos largos\".\n",
        "* Dividir los documentos en secciones cortas llamadas fragmentos (chunks).\n",
        "* Transformar los fragmentos en vectores númericos (Embeddings)\n",
        "* Guardar los embeddings en una base de datos vectorial (Pinecone)\n",
        "* Realizar las consultas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1c38380",
      "metadata": {
        "id": "c1c38380"
      },
      "source": [
        "### Preparando los Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "688ebd8d",
      "metadata": {
        "id": "688ebd8d"
      },
      "outputs": [],
      "source": [
        "pip install -r ./requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5149b52",
      "metadata": {
        "id": "e5149b52"
      },
      "outputs": [],
      "source": [
        "pip install pypdf -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a577a2aa",
      "metadata": {
        "id": "a577a2aa"
      },
      "outputs": [],
      "source": [
        "pip install docx2txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a682695",
      "metadata": {
        "id": "4a682695"
      },
      "outputs": [],
      "source": [
        "pip install wikipedia -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9504ef",
      "metadata": {
        "id": "ff9504ef"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "509811a4",
      "metadata": {
        "id": "509811a4",
        "outputId": "03f97ece-504f-4192-dbd8-c964defca86b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv(find_dotenv(), override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05da8cfa",
      "metadata": {
        "id": "05da8cfa"
      },
      "source": [
        "### Cargar Documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4add4766",
      "metadata": {
        "id": "4add4766"
      },
      "outputs": [],
      "source": [
        "def cargar_documento(archivo):\n",
        "    import os\n",
        "    nombre, extension = os.path.splitext(archivo)\n",
        "    if extension == '.pdf':\n",
        "        from langchain.document_loaders import PyPDFLoader\n",
        "        print(f'Cargando {archivo}...')\n",
        "        loader = PyPDFLoader(archivo)\n",
        "    elif extension == '.docx':\n",
        "        from langchain.document_loaders import Docx2txtLoader\n",
        "        print(f'Cargando {archivo}...')\n",
        "        loader = Docx2txtLoader(archivo)\n",
        "    else:\n",
        "        print('El formato del documento no está soportado!')\n",
        "        return None\n",
        "\n",
        "    data = loader.load()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb186434",
      "metadata": {
        "id": "cb186434"
      },
      "outputs": [],
      "source": [
        "# wikipedia\n",
        "def desde_wikipedia(busqueda, lang='es', load_max_docs=3):\n",
        "    from langchain.document_loaders import WikipediaLoader\n",
        "    loader = WikipediaLoader(query=busqueda, lang=lang, load_max_docs=load_max_docs)\n",
        "    data = loader.load()\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeaca4b0",
      "metadata": {
        "id": "eeaca4b0"
      },
      "source": [
        "### Fragmentar los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f455b9",
      "metadata": {
        "id": "59f455b9"
      },
      "outputs": [],
      "source": [
        "def fragmentar(data, chunk_size=150):\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=20)\n",
        "    fragmentos = text_splitter.split_documents(data)\n",
        "    return fragmentos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0725b19a",
      "metadata": {
        "id": "0725b19a"
      },
      "source": [
        "### Costos OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69bccc16",
      "metadata": {
        "id": "69bccc16"
      },
      "outputs": [],
      "source": [
        "def costo_embedding(texts):\n",
        "    import tiktoken\n",
        "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
        "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
        "    print(f'Total Tokens: {total_tokens}')\n",
        "    print(f'Embedding Cost in USD: {total_tokens / 1000 * 0.0001:.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e8caa61",
      "metadata": {
        "id": "9e8caa61"
      },
      "source": [
        "### Borrando Index de Pinecone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87733198",
      "metadata": {
        "id": "87733198"
      },
      "outputs": [],
      "source": [
        "def borrar_indices(index_name='todos'):\n",
        "    import pinecone\n",
        "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'), environment=os.environ.get('PINECONE_ENV'))\n",
        "\n",
        "    if index_name == 'todos':\n",
        "        indexes = pinecone.list_indexes()\n",
        "        print('Borrando todos los índices ... ')\n",
        "        for index in indexes:\n",
        "            pinecone.delete_index(index)\n",
        "        print('Listo!')\n",
        "    else:\n",
        "        print(f'Borrando el índice: {index_name} ...', end='')\n",
        "        pinecone.delete_index(index_name)\n",
        "        print('Listo')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "094d5a57",
      "metadata": {
        "id": "094d5a57"
      },
      "source": [
        "### Creando Vectores (Embeddings) y subirlos a (Pinecone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74d797a1",
      "metadata": {
        "id": "74d797a1"
      },
      "outputs": [],
      "source": [
        "def creando_vectores(index_name):\n",
        "    import pinecone\n",
        "    from langchain.vectorstores import Pinecone\n",
        "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    pinecone.init(api_key=os.environ.get('PINECONE_API_KEY'),\n",
        "                  environment=os.environ.get('PINECONE_ENV'))\n",
        "\n",
        "    if index_name in pinecone.list_indexes():\n",
        "        print(f'El índice {index_name} ya existe. Cargando los embeddings ... ', end='')\n",
        "        vectores = Pinecone.from_existing_index(index_name, embeddings)\n",
        "        print('Ok')\n",
        "    else:\n",
        "        print(f'Creando el índice {index_name} y los embeddings ...', end='')\n",
        "        pinecone.create_index(index_name, dimension=1536, metric='cosine')\n",
        "        vectores = Pinecone.from_documents(fragmentos, embeddings, index_name=index_name)\n",
        "        print('Ok')\n",
        "\n",
        "    return vectores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c250eb29",
      "metadata": {
        "id": "c250eb29"
      },
      "source": [
        "### Haciendo consultas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390728fb",
      "metadata": {
        "id": "390728fb"
      },
      "outputs": [],
      "source": [
        "def consultas(vectores, pregunta):\n",
        "    from langchain.chains import RetrievalQA\n",
        "    from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "    llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=1)\n",
        "\n",
        "    retriever = vectores.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
        "\n",
        "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "    answer = chain.run(pregunta)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0be00df",
      "metadata": {
        "id": "b0be00df"
      },
      "source": [
        "### Añadiendo memoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4e3edd",
      "metadata": {
        "id": "fc4e3edd"
      },
      "outputs": [],
      "source": [
        "def consulta_con_memoria(vectores, pregunta, memoria=[]):\n",
        "    from langchain.chains import ConversationalRetrievalChain\n",
        "    from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "    llm = ChatOpenAI(temperature=1)\n",
        "    retriever = vectores.as_retriever(search_type='similarity', search_kwargs={'k': 3})\n",
        "\n",
        "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
        "    respuesta = crc({'question': pregunta, 'chat_history': memoria})\n",
        "    memoria.append((pregunta, respuesta['answer']))\n",
        "\n",
        "    return respuesta, memoria"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "386f1ba1",
      "metadata": {
        "id": "386f1ba1"
      },
      "source": [
        "### Resumen Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6025174b",
      "metadata": {
        "id": "6025174b"
      },
      "outputs": [],
      "source": [
        "documento = \"minecraft.pdf\"\n",
        "contenido = cargar_documento(documento)\n",
        "fragmentos = fragmentar(contenido)\n",
        "print(f\"El Número de fragmentos es de: {len(fragmentos)} fragmentos\")\n",
        "costo_embedding(fragmentos)\n",
        "borrar_indices(\"todos\")\n",
        "index_name = 'minecraft'\n",
        "vectores = creando_vectores(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5c5447",
      "metadata": {
        "id": "8b5c5447",
        "outputId": "c537472a-8d0f-44d0-d936-e20b4e837f0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Realiza una pregunta escribe 'salir' para terminar: \n",
            "quien es el creador del juego?\n",
            "El juego Minecraft: Story Mode fue desarrollado por Telltale Games en colaboración con Mojang Studios, la compañía que creó el juego original de Minecraft.\n",
            "Realiza una pregunta escribe 'salir' para terminar: \n",
            "¿Qué me permite hacer el modo espectador?\n",
            "El modo espectador te permite teletransportarte a otros jugadores en la partida. También te permite ver el juego desde el punto de vista de otro jugador o criatura. En algunos casos, puedes cambiar entre las perspectivas de primera y tercera persona. No hay información específica sobre otras funciones que pueda proporcionar el modo espectador.\n"
          ]
        }
      ],
      "source": [
        "memoria = []\n",
        "while True:\n",
        "    pregunta = input(\"Realiza una pregunta escribe 'salir' para terminar: \\n\")\n",
        "    if pregunta == \"salir\":\n",
        "        print(\"Adios!!!\")\n",
        "        break\n",
        "    else:\n",
        "        respuesta, memoria = consulta_con_memoria(vectores, pregunta, memoria)\n",
        "        print(respuesta['answer'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ada0de70",
      "metadata": {
        "id": "ada0de70"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}